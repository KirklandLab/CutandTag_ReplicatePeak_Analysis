configfile: "config/config.yml"

##################################################################
##                         Author Info                          ##
##################################################################

# Author: Kevin A. Boyd
# Email: kevinboyd76@gmail.com
# GitHub: https://github.com/kevinboyd76
# Date Created: March 21, 2025
# Last Modified: August 12, 2025
# Version: 1.2.1
# Adapted scripts from: https://github.com/SansamLab-Pipelines-Genomics/ReplicatePeakAnalyzer
#
# Description: This Snakemake workflow analyzes aligned Cut-and-Tag BAM files
# to identify reproducible consensus peaks across replicates and conditions. It
# performs peak calling on individual and merged BAMs, filters peaks by
# replicate support, generates consensus peak sets, and produces BigWig tracks
# for browser visualization. The pipeline also generates Euler plots to assess
# overlap across replicates and conditions, and heatmaps centered on consensus
# peak midpoints to visualize signal intensity across samples.
#
# This pipeline is designed to run downstream of the CutandTag_Alignment_QC
# workflow (https://github.com/KirklandLab/CutandTag_Alignment_QC), which
# produces aligned and filtered BAM files.

##################################################################
##                  Specific Steps in Pipeline                  ##
##################################################################

#  Steps:
#  1) Merge replicate BAMs based on the `set` column in samples.csv
#  2) Call peaks using MACS2 on both individual and merged BAMs
#  3) Generate consensus peaks by filtering merged peaks based on replicate support
#  4) Extract reads from merged BAMs over consensus peak regions
#  5) Convert extracted reads to sorted BAM and BigWig formats
#  6) Create Euler diagrams to visualize replicate and condition-level overlaps
#  7) Calculate peak midpoints and overlaps across sets
#  8) Generate heatmaps centered on consensus peak midpoints
#     – Heatmap generation is toggleable in config.yml
#     – Sample order is controlled by the `sampleOrder` field
#  9) (Optional) Run standalone heatmap script on custom BED regions

#  Outputs:
#    • Merged BAMs for each replicate set
#    • MACS2 peak files (individual and merged)
#    • Consensus peak BED files (filtered by replicate overlap)
#    • Sorted BAMs and BigWigs over consensus peaks
#    • Euler diagrams (PDF)
#    • Consensus midpoint BED files
#    • Heatmaps of signal intensity (PDF)
#    • Optional custom heatmaps from user-defined BEDs

##################################################################
##                    Define input functions                    ##
##################################################################

import pandas as pd
import os

# Read the CSV file and set an index using the values in the "sample" column.
samples_table = pd.read_csv(config["samples_csv"]).set_index("sample", drop=False)

# define sets
all_sets = samples_table["set"]
unique_sets_in_order = list(dict.fromkeys(all_sets))

# define unique marks / conditions
unique_marks = list(dict.fromkeys(samples_table["mark"]))
unique_conditions = list(dict.fromkeys(samples_table["condition"]))

# filter samples by their set
def filter_sample_by_set(Set, samples_table):
    return list(set(samples_table[samples_table["set"] == Set]["sample"]))

# filter sets by condition
def sets_for_mark_condition(mark, condition, df):
    subset = df[(df["mark"] == mark) & (df["condition"] == condition)]
    return list(set(subset["set"]))


##################################################################
##                      Toggle HeatPlots                        ##
##################################################################

# Get the flags from the config (defaut True if not specified)
generate_consensus_heatplot = config.get("heatplot_all", True)
generate_unique_heatplot = config.get("heatplot_unique", True)

# Define consensus heatplot targets conditionally
consensus_heatplot_targets = []
if generate_consensus_heatplot:
    consensus_heatplot_targets = [
        "results/heatmap/Beds_All_Samples.gz",
        "results/heatmap/HeatPlots_All_Samples.png"
    ]

# Define unique heatplot targets conditionally
unique_heatplot_targets = []
if generate_unique_heatplot:
    unique_heatplot_targets = [
        "results/heatmap/Beds_Unique_Samples.gz",
        "results/heatmap/HeatPlots_Unique_Samples.png"
    ]

##################################################################
##                          Rule All                            ##
##################################################################

rule all:
    input:
        expand("results/macs2Peaks/{sample}_0.05_peaks.narrowPeak", sample=samples_table.index),
        expand("results/mergedBam/{Set}_merged.bam", Set=list(set(samples_table["set"]))),
        expand("results/mergedPeaks/{Set}_merged_0.05_peaks.narrowPeak", Set=list(set(samples_table["set"]))),
        expand("results/consensusPeaks/{Set}_consensus_peaks.bed", Set=list(set(samples_table["set"]))),
        expand("results/consensusPeaks/{Set}_filtered.bam", Set=list(set(samples_table["set"]))),
        expand("results/consensusPeaks/{Set}_consensus_peaks.bw", Set=list(set(samples_table["set"]))),
        expand("results/eulerPlot/{Set}_eulerPlot.pdf", Set=list(set(samples_table["set"]))),
        "results/overlaps/MidpointOverlaps.bed",
        expand("results/consensusPeaks/{Set}_unique_MP.bed", Set=list(set(samples_table["set"]))),
        consensus_heatplot_targets,
        expand("results/eulerPlotMarkByCondition/{mark}_eulerPlot.pdf", mark=unique_marks),
        unique_heatplot_targets


##################################################################
##                 MACS2 Peak Calling Individual                ##
##################################################################

rule call_peaks_with_macs2:
    input:
        bam=lambda wildcards: samples_table.loc[wildcards.sample, "bam"]
    output:
        peaks="results/macs2Peaks/{sample}_0.05_peaks.narrowPeak",
        summary="results/macs2Peaks/{sample}_macs2Peak_summary.txt"
    params:
        genome=config["genome"],
        qvalue=config["macs2_qvalue"],
        sample_name="{sample}",
        output_dir="results/macs2Peaks/"
    envmodules:
        config["macs2"]
    threads: 4
    log:
        "results/logs/call_peaks_with_macs2.{sample}.snakemake.log"
    shell:
        """
        macs2 callpeak -t {input.bam} \
        -g {params.genome} -f BAMPE -n {params.sample_name}_{params.qvalue} \
        --outdir {params.output_dir} -q {params.qvalue} --keep-dup all --nomodel \
        2>{output.summary}
        """


##################################################################
##                       Merge Bams By Set                      ##
##################################################################

rule merge_bams_per_set:
    input:
        lambda wildcards: [
            samples_table.loc[sample, "bam"]
            for sample in filter_sample_by_set(wildcards.Set, samples_table)
        ]
    output:
        bam="results/mergedBam/{Set}_merged.bam",
        bai="results/mergedBam/{Set}_merged.bam.bai"
    envmodules:
        config["samtools"]
    threads: 4
    log:
        "results/logs/merge_bams_per_set.{Set}.snakemake.log"
    shell:
        """
        {{
            TMP_DIR=$(mktemp -d)
            TMP_SORTED_BAMS=""
    
            for bam in {input}; do
                base=$(basename $bam .bam)
                sorted_bam=$TMP_DIR/${{base}}_sorted.bam
                samtools sort -@ {threads} -o $sorted_bam $bam
                TMP_SORTED_BAMS="$TMP_SORTED_BAMS $sorted_bam"
            done
    
            samtools merge -@ {threads} {output.bam} $TMP_SORTED_BAMS
            samtools index -@ {threads} {output.bam}
            rm -r $TMP_DIR
        }} > {log} 2>&1
    """


##################################################################
##                   MACS2 Peak Calling Merged                  ##
##################################################################

rule call_macs2_on_merged_bam:
    input:
        bam="results/mergedBam/{Set}_merged.bam"
    output:
        peaks="results/mergedPeaks/{Set}_merged_0.05_peaks.narrowPeak"
    params:
        genome=config["genome"],
        qvalue=config["macs2_qvalue"],
        sample_name="{Set}_merged",
        outdir="results/mergedPeaks/"
    envmodules:
        config["macs2"]
    threads: 4
    log:
        "results/logs/call_macs2_on_merged_bam.{Set}.snakemake.log"
    shell:
        """
        macs2 callpeak -t {input.bam} \
        -g {params.genome} -f BAMPE -n {params.sample_name}_{params.qvalue} \
        --outdir {params.outdir} -q {params.qvalue} --keep-dup all --nomodel > {log} 2>&1
        """


##################################################################
##              Generate Consensus Peaks by Overlap             ##
##################################################################

rule generate_consensus_peaks_by_overlap:
    input:
        merged_peaks="results/mergedPeaks/{Set}_merged_0.05_peaks.narrowPeak",
        replicate_peaks=lambda wildcards: expand(
            "results/macs2Peaks/{sample}_0.05_peaks.narrowPeak",
            sample=filter_sample_by_set(wildcards.Set, samples_table)
        )
    output:
        consensus="results/consensusPeaks/{Set}_consensus_peaks.bed"
    params:
        min_overlap=config["minNumberOfSampleOverlaps"]
    envmodules:
        config["R"],
        config["bioconductor"]
    threads: 2
    log:
        "results/logs/generate_consensus_peaks_by_overlap.{Set}.snakemake.log"
    shell:
        """
        Rscript scripts/filterConsensusFromMergedPeakSet.R {input.merged_peaks} {input.replicate_peaks} {params.min_overlap} {output.consensus} > {log} 2>&1
        """


##################################################################
##                  Extract Reads for Consensus                 ##
##################################################################

rule extract_reads_for_consensus:
    input:
        merged_bam="results/mergedBam/{Set}_merged.bam",
        consensus_bed="results/consensusPeaks/{Set}_consensus_peaks.bed"
    output:
        filtered_bam="results/consensusPeaks/{Set}_filtered.bam",
        index="results/consensusPeaks/{Set}_filtered.bam.bai"
    envmodules:
        config["samtools"]
    threads: 4
    log:
        "results/logs/extract_reads_for_consensus.{Set}.snakemake.log"
    shell:
        """
        samtools view -@ {threads} -b {input.merged_bam} -L {input.consensus_bed} > {output.filtered_bam}
        samtools index -@ {threads} {output.filtered_bam} >> {log} 2>&1
        """


##################################################################
##                  Create BigWig from Consensus                ##
##################################################################

rule create_bigwig_from_consensus:
    input:
        bam="results/consensusPeaks/{Set}_filtered.bam"
    output:
        bigwig="results/consensusPeaks/{Set}_consensus_peaks.bw"
    params:
        bin_size=config["binSize"],
        genome_size=config["effective_genome_size"]
    envmodules:
        config["deeptools"]
    threads: 4
    log:
        "results/logs/create_bigwig_from_consensus.{Set}.snakemake.log"
    shell:
        """
        bamCoverage -p {threads} --bam {input.bam} \
        --outFileName {output.bigwig} \
        --binSize {params.bin_size} \
        --effectiveGenomeSize {params.genome_size} \
        --normalizeUsing CPM > {log} 2>&1
        """


##################################################################
##             Make Euler Plot of Overlaps from Beds            ##
##################################################################

rule make_euler_plot_of_overlaps_from_beds:
    input:
        beds=lambda wc: [
            f"results/macs2Peaks/{sample}_0.05_peaks.narrowPeak"
            for sample in filter_sample_by_set(wc.Set, samples_table)
        ]
    output:
        rds="results/eulerPlot/{Set}_eulerPlot.rds",
        pdf="results/eulerPlot/{Set}_eulerPlot.pdf"
    params:
        font_size=config["EulerFontSize"],
        colors=config["EulerColors1"],
        pdf_width=config["EulerWidth"],
        pdf_height=config["EulerHeight"],
        set_names=lambda wc: ",".join(filter_sample_by_set(wc.Set, samples_table))
    envmodules:
        config["R"],
        config["bioconductor"]
    threads: 2
    log:
        "results/logs/make_euler_plot_of_overlaps_from_beds.{Set}.snakemake.log"
    shell:
        """
        BED_FILES=$(echo {input.beds} | tr ' ' ',')
        Rscript scripts/makeEulerPlotOfBedOverlaps.R "$BED_FILES" "{params.set_names}" \
            {output.rds} {output.pdf} {params.font_size} "{params.colors}" \
            {params.pdf_width} {params.pdf_height} > {log} 2>&1
        """


##################################################################
##                   Midpoint and Peak Overlaps                 ##
##################################################################

rule midpoint_and_peak_overlaps:
    input:
        reproducible_beds=expand("results/consensusPeaks/{Set}_consensus_peaks.bed", Set=list(set(samples_table["set"])))
    output:
        midpoint="results/overlaps/MidpointOverlaps.bed",
        peak="results/overlaps/PeakOverlaps.bed",
        unique=expand("results/consensusPeaks/{Set}_unique_MP.bed", Set=list(set(samples_table["set"])))
    params:
        out_dir="results/overlaps/"
    envmodules:
        config["R"],
        config["bioconductor"]
    threads: 2
    log:
        "results/logs/midpoint_and_peak_overlaps.snakemake.log"
    shell:
        """
        Rscript scripts/midpointAndPeakOverlaps.R {input.reproducible_beds} {params.out_dir} > {log} 2>&1
        """


##################################################################
##               Generate Heatmap For All Samples               ##
##################################################################

rule generate_heatmap:
    input:
        bigwigs=expand("results/consensusPeaks/{Set}_consensus_peaks.bw", Set=unique_sets_in_order),
        midpoints="results/overlaps/MidpointOverlaps.bed"
    output:
        matrix="results/heatmap/Beds_All_Samples.gz",
        heatmap="results/heatmap/HeatPlots_All_Samples.png"
    params:
        before_region=3000,
        after_region=3000,
        processors=8,
        refPointName="Center",
        regionsName="All Midpoints",
        sampleOrder=config["sampleOrder"].replace(",", " "),
        samplesLabel=lambda wildcards, input: " ".join(
            [os.path.basename(x).replace("_consensus_peaks.bw", "") for x in input.bigwigs]
        )
    envmodules:
        config["deeptools"]
    threads: 8
    log:
        "results/logs/generate_heatmap.snakemake.log"
    shell:
        """
        computeMatrix reference-point -S {input.bigwigs} -R {input.midpoints} \
        --outFileName {output.matrix} -a {params.after_region} -b {params.before_region} \
        --numberOfProcessors {threads} > {log} 2>&1

        plotHeatmap -m {output.matrix} -out {output.heatmap} \
        --dpi 1000 --sortUsing sum --sortUsingSamples {params.sampleOrder} \
        --refPointLabel "{params.refPointName}" \
        --regionsLabel "{params.regionsName}" \
        --samplesLabel {params.samplesLabel} >> {log} 2>&1
        """

##################################################################
##                Euler Plot Conditions by Mark                 ##
##################################################################

# Get unique (mark, condition) combinations in order
def mark_condition_combos(df):
    return sorted(set(zip(df["mark"], df["condition"])))

# Get the sets that correspond to a mark+condition combo
def sets_for_mark_condition(mark, condition, df):
    return sorted(set(df[(df["mark"] == mark) & (df["condition"] == condition)]["set"]))

# Build paths to the consensus peak BEDs for each condition of a mark
def bed_paths_for_mark(mark, df):
    conditions = sorted(set(df[df["mark"] == mark]["condition"]))
    return [
        f"results/consensusPeaks/{sets_for_mark_condition(mark, cond, df)[0]}_consensus_peaks.bed"
        for cond in conditions
    ]

# Just return the condition labels, like "C,T"
def joined_conditions_for_mark(wc):
    return ",".join(sorted(set(samples_table[samples_table["mark"] == wc.mark]["condition"])))

rule euler_plot_by_mark:
    input:
        lambda wc: bed_paths_for_mark(wc.mark, samples_table)
    output:
        rds="results/eulerPlotMarkByCondition/{mark}_eulerPlot.rds",
        pdf="results/eulerPlotMarkByCondition/{mark}_eulerPlot.pdf"
    params:
        font_size=config["EulerFontSize"],
        colors=config["EulerColors2"],
        pdf_width=config["EulerWidth"],
        pdf_height=config["EulerHeight"],
        set_names=lambda wc: joined_conditions_for_mark(wc)
    envmodules:
        config["R"],
        config["bioconductor"]
    threads: 2
    log:
        "results/logs/euler_plot_by_mark.{mark}.snakemake.log"
    shell:
        """
        # Turn the list of input .bed files into a comma-separated string
        BED_FILES="$(echo {input} | tr ' ' ',')"

        # Pull in your precomputed set_names from params
        SET_NAMES="{params.set_names}"

        echo "BED_FILES => $BED_FILES"
        echo "SET_NAMES => $SET_NAMES"

        Rscript scripts/makeEulerPlotOfBedOverlaps.R \
            "$BED_FILES" \
            "$SET_NAMES" \
            {output.rds} \
            {output.pdf} \
            {params.font_size} \
            "{params.colors}" \
            {params.pdf_width} \
            {params.pdf_height} > {log} 2>&1
        """

##################################################################
##                 Generate Unique Bed Heatmaps                 ##
##################################################################

# Preserve the original order from samples table:
unique_sets_in_order = list(dict.fromkeys(samples_table["set"].tolist()))

rule generate_unique_heatmap:
    input:
        uniqueBeds = expand("results/consensusPeaks/{Set}_unique_MP.bed", Set=unique_sets_in_order),
        bigwigs   = [f"results/consensusPeaks/{s}_consensus_peaks.bw" for s in unique_sets_in_order]
    output:
        matrix  = "results/heatmap/Beds_Unique_Samples.gz",
        heatmap = "results/heatmap/HeatPlots_Unique_Samples.png"
    params:
        before_region = 3000,
        after_region  = 3000,
        processors    = 8,
        refPointName  = "Center",
        # Convert "1,2,3,4,5,6" to "1 2 3 4 5 6" for deepTools:
        sampleOrder   = config["sampleOrder"].replace(",", " "),
        # Generate sample labels by extracting the basename (in the order of the input bigWig files)
        # Join with spaces instead of commas
        samplesLabel  = lambda wildcards, input: " ".join(
            [os.path.basename(x).replace("_consensus_peaks.bw", "")
             for x in input.bigwigs]
        ),
        regionLabels  = lambda wildcards, input: " ".join(
            [os.path.basename(x).replace("_unique_MP.bed", "")
             for x in input.uniqueBeds]
        )
    envmodules:
        config["deeptools"]
    threads: 8
    log:
        "results/logs/generate_unique_heatmap.snakemake.log"
    shell:
        """
        computeMatrix reference-point \
            -S {input.bigwigs} \
            -R {input.uniqueBeds} \
            --outFileName {output.matrix} \
            -a {params.after_region} -b {params.before_region} \
            --numberOfProcessors {threads} > {log} 2>&1

        plotHeatmap \
            -m {output.matrix} \
            -out {output.heatmap} \
            --dpi 1000 \
            --sortUsing sum \
            --sortUsingSamples {params.sampleOrder} \
            --refPointLabel "{params.refPointName}" \
            --samplesLabel {params.samplesLabel} \
            --regionsLabel {params.regionLabels} >> {log} 2>&1
        """
